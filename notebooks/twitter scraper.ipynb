{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTJ8IuShHON2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import re\n",
    "import tweepy\n",
    "import configparser\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import statistics\n",
    "from typing import List\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# create the authentication object\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "\n",
    "#Set the access token and access token secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "#Creat the API object while passing in the auth information\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# extract 100 tweets from twitter timeline\n",
    "\n",
    "\n",
    "def get_tweets (keyword: str):\n",
    "    all_tweets = []\n",
    "    corsor = tweepy.Cursor(api.search, q=keyword , tweet_mode=\"extended\",lang=\"ar\"). items (3000)\n",
    "\n",
    "    for tweet in corsor :\n",
    "         all_tweets.append(tweet.full_text)\n",
    "    return all_tweets\n",
    "\n",
    "\n",
    "# clean the data\n",
    "def clean_tweets (all_tweets: List[str]):\n",
    "    tweets_clean = []\n",
    "    for tweet in all_tweets:\n",
    "      tweet = re.sub(\"@[A-Za-z0-9_]+\",\"\", tweet)\n",
    "      tweet = re.sub(\"\\n\",\" \", tweet)\n",
    "      tweets_clean.append(tweet) # remove and clean the tweet from any \"#\" and hyper link\n",
    "\n",
    "    tweets_clean= [tweet.replace(\":\",\"\") for tweet in tweets_clean]\n",
    "    return tweets_clean\n",
    "\n",
    "# cleaned_tweets = clean_tweets(all_tweets)\n",
    "\n",
    "\n",
    "def creatDataFrame(cleaned_tweets):\n",
    "  #Create a dataframe with a column called Tweets\n",
    "  df = pd.DataFrame( [tweet for tweet in cleaned_tweets] , columns=['Tweets'])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xTlFC61OlRC"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "arb_stopwords = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "\n",
    "def modify_arabic_post(text):\n",
    "  text = re.sub('_+', ' ', text)\n",
    "    ## To find arabic Tashkeel\n",
    "  arabic_diacritics = re.compile(\"\"\"\n",
    "                              ّ    | # Tashdid\n",
    "                              َ    | # Fatha\n",
    "                              ً    | # Tanwin Fath\n",
    "                              ُ    | # Damma\n",
    "                              ٌ    | # Tanwin Damm\n",
    "                              ِ    | # Kasra\n",
    "                              ٍ    | # Tanwin Kasr\n",
    "                              ْ    | # Sukun\n",
    "                              ـ     # Tatwil/Kashida\n",
    "                          \"\"\", re.VERBOSE)\n",
    "  # Remove Tashkeel\n",
    "  input_str = re.sub(arabic_diacritics, '', text)\n",
    "  # Replace digits\n",
    "  input_str = re.sub('[0-9]+', 'ارقام', input_str)\n",
    "  s='٠١٢٣٤٥٦٧٨٩'\n",
    "  input_str = re.sub('['+s+']+', 'ارقام', input_str)\n",
    "  # Remove punctuation\n",
    "  input_str = re.sub(r'[^\\w\\s]',' ',input_str)\n",
    "  # Remove underscore\n",
    "  input_str = re.sub('_+' , ' ', input_str)\n",
    "  # Remove newLine\n",
    "  input_str = re.sub(r'\\n+', ' ', input_str)\n",
    "  # Normalization\n",
    "  input_str = re.sub(\"[إأآا]\", \"ا\", input_str)\n",
    "  input_str = re.sub(\"گ\", \"ك\", input_str)\n",
    "  # Remove duplicate ch more than 2\n",
    "  pattern=re.compile(r\"(.)\\1{1,}\",re.DOTALL)\n",
    "  input_str = pattern.sub(r\"\\1\\1\",input_str)\n",
    "  # Delete repeated words\n",
    "  input_str = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', input_str)\n",
    "  # Delete non arabic characters\n",
    "  regex = re.compile('[^0-9\\u0621-\\u064A\\u0660-\\u0669 ]')\n",
    "  input_str = regex.sub('', input_str)\n",
    "  # Delete consective spaces and spaces in begining and end\n",
    "  input_str = input_str.strip()\n",
    "  input_str = re.sub('\\s+',' ',input_str)\n",
    "  input_str = re.sub(' +', ' ', input_str)\n",
    "  #stop word\n",
    "  filtered_sentence = [w for w in input_str.split() if not w in arb_stopwords]\n",
    "  input_str= ' '.join(filtered_sentence)\n",
    "  #punctuation\n",
    "  translator = str.maketrans('', '', punctuations_list)\n",
    "  input_str= input_str.translate(translator)\n",
    "  return input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZj-bcWDPA7d"
   },
   "outputs": [],
   "source": [
    "df['Tweets']=df['Tweets'].apply(modify_arabic_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Et2h06kkheAC"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3MaQF2CMz7V"
   },
   "outputs": [],
   "source": [
    "def aa(input_str):\n",
    "  input_str = re.sub(\"معصيتي راحتي\", \" \", input_str)\n",
    "  input_str = re.sub(\"معصيت راحتي\", \" \", input_str)\n",
    "  return input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGC-y-NuN7GP"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LbaBPbhij--"
   },
   "outputs": [],
   "source": [
    "df['Tweets']=df['Tweets'].apply(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJFsbYYNNTk7"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UYA7UXFPcqO"
   },
   "outputs": [],
   "source": [
    "df.to_csv('aa.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbAXKT7WP2K3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
